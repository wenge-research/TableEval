system_messages:
  cot: "You are a helpful assistant. Think step-by-step and provide a detailed and helpful response."
  direct: ""

evaluation_prompt:
  prompt: '## 目标\n请将大模型的回答与用户提供的参考答案进行对比，步骤如下：\n\n1. 提取关键答案\n   1. 定位大模型回答的“最终总结”，逐个对照参考答案中的子问题，从大模型的“最终总结”中提取每个问题对应所有关键回答。关键回答应仅包含核心的、直接回答问题的内容。\n   2. 对已识别出的某个关键回答进行补充说明的内容，应与该关键回答合并为一个整体，不要拆分成新的答案要素。只有在内容明显独立、可与参考答案中不同要素相对应时，才视为新答案。\n2. 对比并标注：将提取出的回答与参考答案逐一对比，按以下标准进行标注：\n   1. 错误答案（false）：如果大模型多输出了一些要素，并且这些要素与参考答案无法对应或仅是多余的补充信息（不是在同一个要素中补充，而是产生了多余答案要素），则判定为错误。\n   2. 正确答案（true）：如果该条回答与参考答案某一要素含义一致或高度吻合，视为正确。\n   3. 注意：每个从大模型回答中提取出的答案要素，都要有相应的 true 或 false 标签，确保每个回答要素都被检查。\n\n### 输出格式\n```\n{{\n  "问题列表": [\n    {{\n      "问题": "子问题1",\n      "参考答案": ["答案1", "答案2"],\n      "大模型的回答": ["关键回答1", "关键回答2"],\n      "是否正确": [true, false]\n    }},\n    {{\n      "问题": "子问题2",\n      "参考答案": ["答案1"],\n      "大模型的回答": ["关键回答1", "关键回答2", "关键回答3", "关键回答4"],\n      "是否正确": [false, true, false, false]\n    }}\n  ]\n}}\n```\n\n### 参考答案\n{answer}\n'